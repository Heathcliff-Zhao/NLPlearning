{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('glove-twitter-100')\n",
    "word_dict=set(model.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "sw_nltk = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"F:/Kaggle/input/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"F:/Kaggle/input/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_characters(input_string):\n",
    "    # Use regular expressions to remove all special characters, but keep spaces\n",
    "    cleaned_string = re.sub(r\"[^a-zA-Z0-9\\s]+\", \"\", input_string)\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data,havetarget=True,meanofword=False):\n",
    "    tmp_train_comments_tok=[tokenizer.tokenize(remove_special_characters(line.lower())) for line in data['text']]\n",
    "    train_comments_tok=[]\n",
    "    it=0\n",
    "    for line in tmp_train_comments_tok:\n",
    "        train_comments_tok.append([])\n",
    "        for word in line:\n",
    "            if word not in sw_nltk and word in word_dict:\n",
    "                train_comments_tok[it].append(word)\n",
    "        it+=1\n",
    "    blank_comment_index=list()\n",
    "    sentense_embedding=list()\n",
    "    cnt=0\n",
    "    for line in train_comments_tok:\n",
    "        now=list()\n",
    "        for word in line:\n",
    "            now.append(model.get_vector(word))\n",
    "        if len(now):\n",
    "            if meanofword:\n",
    "                sentense_embedding.append(now)\n",
    "            else:\n",
    "                sentense_embedding.append(np.array(now).mean(0))\n",
    "        else:\n",
    "            blank_comment_index.append(cnt)\n",
    "        cnt+=1\n",
    "    sentense_embedding=np.array(sentense_embedding)\n",
    "    data=data.drop(blank_comment_index)\n",
    "    if havetarget:\n",
    "        return sentense_embedding,data['target']\n",
    "    else:\n",
    "        return sentense_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_embedding,train_target=clean(train_df)\n",
    "test_sent_embedding=clean(test_df,havetarget=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28261\\AppData\\Local\\Temp\\ipykernel_14524\\837246695.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sentense_embedding=np.array(sentense_embedding)\n"
     ]
    }
   ],
   "source": [
    "train_sentense_wordembedding,train_target=clean(train_df,meanofword=True)\n",
    "test_sentence_wordembedding=clean(test_df,havetarget=False,meanofword=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxlen(listoflongshortlist):\n",
    "    max_len=0\n",
    "    for i in listoflongshortlist:\n",
    "        max_len=max(max_len,len(i))\n",
    "    return max_len\n",
    "max_len=max(get_maxlen(train_sentense_wordembedding),get_maxlen(test_sentence_wordembedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(listoflongshortlist):\n",
    "    for i in range(len(listoflongshortlist)):\n",
    "        listoflongshortlist[i]=((listoflongshortlist[i]-np.min(listoflongshortlist[i]))/np.max(listoflongshortlist[i])).tolist()\n",
    "        while len(listoflongshortlist[i])!=max_len:\n",
    "            # listoflongshortlist[i].append(np.zeros_like(listoflongshortlist[i][0]).tolist())\n",
    "            listoflongshortlist[i].append(np.mean(listoflongshortlist[i],axis=0).tolist())\n",
    "    return torch.Tensor(listoflongshortlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentense_wordembedding=pad(list(train_sentense_wordembedding))\n",
    "test_sentence_wordembedding=pad(list(test_sentence_wordembedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "    nn.Conv2d(1,4,kernel_size=(3,100)),nn.Dropout(),\n",
    "    nn.MaxPool2d(kernel_size=(23-3+1,1)),\n",
    "    nn.Flatten(1,3),\n",
    "    nn.Linear(4,2),nn.Softmax(1)\n",
    ")\n",
    "optimizer=optim.Adam(net.parameters(),lr=0.00001)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "device=torch.device('cuda')\n",
    "net=net.to(device)\n",
    "loss=loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in net.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target=torch.tensor(train_target.values).to(device)\n",
    "train_sentense_wordembedding=train_sentense_wordembedding.to(device)\n",
    "dataset=TensorDataset(train_sentense_wordembedding,train_target)\n",
    "data_iter=DataLoader(dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs=800\n",
    "# for epoch in range(num_epochs):\n",
    "#     for x,y in data_iter:\n",
    "#         optimizer.zero_grad()\n",
    "#         l=loss(net(x.unsqueeze(1)),y)\n",
    "#         l.mean().backward()\n",
    "#         optimizer.step()\n",
    "#     if (epoch+1)%50==1:\n",
    "#         print(loss(net(train_sentense_wordembedding.unsqueeze(1)),train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4962, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs=2000\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max = (epochs // 9) + 1)\n",
    "k_fold=5\n",
    "batch_size=64\n",
    "for i in range(k_fold):\n",
    "    i_data=get_k_fold_data(k_fold,i,train_sentense_wordembedding,train_target)\n",
    "    data_iter = d2l.load_array((i_data[0], i_data[1]), batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        for x,y in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            l=loss(net(x.unsqueeze(1)),y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        if (epoch+1)%50==0:\n",
    "            print(loss(net(i_data[2].unsqueeze(1)),i_data[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "ttt=net(test_sentence_wordembedding.to(device).unsqueeze(1)).argmax(axis=1)\n",
    "ttt=ttt.cpu().detach().numpy()\n",
    "ttt=pd.DataFrame(ttt)\n",
    "ttt.to_csv('F:/Kaggle/NLP/Natural Language Processing with Disaster Tweets/CNN-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
